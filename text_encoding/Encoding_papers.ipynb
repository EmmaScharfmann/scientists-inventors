{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191406e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fs01/spec1142/anaconda3/envs/patents/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import psycopg2\n",
    "import time \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "import logging\n",
    "import tqdm as notebook_tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f455458e-5b22-41b8-8ab0-25551461d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/fs01/spec1142/Emma/GateKeepers/' + \"database.txt\", \"r\")\n",
    "user , password = f.read().split()\n",
    "\n",
    "main_path = '/home/fs01/spec1142/Emma/GateKeepers/Text_encoding/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c19dd1-6a1c-456f-aa3b-fda738e2831f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get papers that are not encoded yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1b80c-9dbe-46ac-a451-8438026a8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "##query the work_ids that are in the works table but not in the encoded_works table\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "#establishing the connection\n",
    "conn = psycopg2.connect(\"user=\" + user + \" password=\" + password)\n",
    "\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "#Creating table as per requirement\n",
    "sql =\"\"\"SELECT work_id \n",
    "        FROM ( SELECT work_id , title , abstract FROM works_OpenAlex WHERE abstract != '' AND  abstract != 'nan') AS w\n",
    "        WHERE  NOT EXISTS (\n",
    "                   SELECT work_id\n",
    "                   FROM   encoded_works_OpenAlex\n",
    "                   WHERE  work_id = w.work_id\n",
    "                   )\n",
    "        ;\"\"\"\n",
    "cursor.execute(sql)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dic_works = {} \n",
    "\n",
    "for line in tqdm(result): \n",
    "    work_id = line[0]\n",
    "    dic_works[work_id] = {}\n",
    "    \n",
    "    \n",
    "\n",
    "## save the ids\n",
    "    \n",
    "import json\n",
    "json = json.dumps(dic_works)\n",
    "f = open(path + 'new_papers_to_encode.json',\"w\")\n",
    "f.write(json)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b33de-e0e6-4e6f-8716-159b992d507e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get text (title and abstract) lf the papers that are not encoded yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174ae98-c775-47c0-97c5-28b52adc8466",
   "metadata": {},
   "source": [
    "run \"get_texts.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056bdf3a-8195-421e-90e1-5eb29a898444",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encode the texts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76409ad2-1262-4390-9e41-8f3348b24107",
   "metadata": {},
   "source": [
    "run \"encoding.py\"                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acf7bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load encoding to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c9095-17b4-408f-bd0f-2f0f0f2c2fd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create table (if does not already exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb0c5b-f1f9-41ab-bb4e-111b2a3677eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"encoded_works_OpenAlex\"\n",
    "\n",
    "schema =\"\"\"CREATE TABLE  \"\"\" + table_name + \"\"\" (\n",
    "   work_id VARCHAR(20),\n",
    "   encoded_title TEXT,\n",
    "   encoded_abstract TEXT\n",
    "   );\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#establishing the connection\n",
    "conn = psycopg2.connect(\"user=\" + user + \" password=\" + password)\n",
    "\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Doping EMPLOYEE table if already exists.\n",
    "cursor.execute(\"DROP TABLE IF EXISTS \" + table_name)\n",
    "\n",
    "#Creating table as per requirement\n",
    "\n",
    "sql = schema\n",
    "\n",
    "\n",
    "cursor.execute(sql)\n",
    "print(\"Table created successfully........\")\n",
    "conn.commit()\n",
    "##Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc0d235-82da-44a5-8f3d-49130ec20ff4",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5792dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fs01/spec1142/anaconda3/envs/patents/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "  9%|▉         | 1/11 [03:53<38:51, 233.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [07:14<32:08, 214.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 3/11 [10:15<26:35, 199.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 4/11 [14:17<25:13, 216.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 5/11 [18:21<22:36, 226.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 6/11 [22:34<19:36, 235.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 7/11 [25:19<14:08, 212.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 8/11 [28:11<09:58, 199.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 9/11 [30:55<06:16, 188.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 10/11 [33:31<02:58, 178.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [36:05<00:00, 196.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index_columns = ['work_id']\n",
    "\n",
    "table_name = \"encoded_works_OpenAlex\"\n",
    "\n",
    "#establishing the connection\n",
    "conn = psycopg2.connect(\"user=\" + user + \" password=\" + password)\n",
    "\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for k in tqdm(range(13)):\n",
    "    \n",
    "    \n",
    "    file = \"new_works_encoded_\" + str(k) + \".tsv\"\n",
    "    path =  main_path + \"OA_encoded_works/\" + file\n",
    "\n",
    "    with open(path) as f:\n",
    "        cursor.copy_expert(\"COPY \" + table_name + \" FROM STDIN WITH DELIMITER E'\\t' CSV HEADER\", f)\n",
    "\n",
    "    conn.commit()\n",
    "    print(k)\n",
    "\n",
    "\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e08a8-780f-44fd-862b-7754becd4631",
   "metadata": {},
   "source": [
    "### Index table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc536d-1e3c-4fe3-80eb-023e61bda71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##establishing the connection\n",
    "conn = psycopg2.connect(\"user=\" + user + \" password=\" + password)\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "for index_column in index_columns:\n",
    "   #Creating table as per requirement\n",
    "    sql ='''CREATE INDEX ''' + index_column + '_' + table_name + ''' ON '''+ table_name +'''(''' + index_column + ''');'''\n",
    "    cursor.execute(sql)\n",
    "    print(\"Table indexed successfully........\")\n",
    "conn.commit()\n",
    "#Closing the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5363a-2021-424e-b52a-a24ca7432583",
   "metadata": {},
   "source": [
    "## Load data to GoogleCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d4f4a-89ae-40d5-adad-1fe8614fccbc",
   "metadata": {},
   "source": [
    "### upload data from Google Cloud to the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8c2c0-8daf-48f2-994a-d7d7cad2c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from tqdm import tqdm\n",
    "import psycopg2\n",
    "\n",
    "## connection to Google Cloud \n",
    "path_to_private_key = main_path + \"openalex-lee-c532eb059285.json\"\n",
    "client_storage = storage.Client.from_service_account_json(json_credentials_path=path_to_private_key)\n",
    "bucket = client_storage.bucket('openalex-lee')\n",
    "\n",
    "# Get blobs in specific subirectory\n",
    "blobs_specific = list(bucket.list_blobs(prefix='OpenAlex/works_encoded/'))\n",
    "list_files = [ str(elem).split(\", \")[1] for elem in blobs_specific][::-1]\n",
    "\n",
    "\n",
    "for file in tqdm(list_files[13+14+3:]):\n",
    "    blob = bucket.blob(file)\n",
    "\n",
    "    ##establishing the connection\n",
    "    conn = psycopg2.connect(\"user=\" + user + \" password=\" + password)\n",
    "\n",
    "    ##Creating a cursor object using the cursor() method\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    table_name = \"encoded_works_OpenAlex\"\n",
    "\n",
    "    with blob.open(\"r\") as f:\n",
    "        cursor.copy_expert(\"COPY \" + table_name + \" FROM STDIN WITH DELIMITER E'\\t' CSV HEADER WHERE LEFT(work_id,1) = 'W'\", f)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    #Closing the connection\n",
    "    conn.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17511645-18a0-47c0-81da-058df6c7f1fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Upload file from local to Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9550671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [02:49<28:17, 169.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_2.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_2.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [04:53<21:24, 142.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_3.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_3.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 3/11 [07:17<19:04, 143.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_4.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_4.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 4/11 [09:21<15:51, 135.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_5.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_5.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 5/11 [11:47<13:57, 139.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_6.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_6.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 6/11 [13:44<10:58, 131.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_7.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_7.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 7/11 [16:10<09:05, 136.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_8.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_8.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 8/11 [18:47<07:08, 142.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_9.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_9.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 9/11 [21:00<04:39, 139.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_10.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_10.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 10/11 [23:02<02:14, 134.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_11.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_11.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [24:59<00:00, 136.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/fs01/spec1142/Emma/Download_OpenAlex/OA_encoded_works/new_works_encoded_12.tsv uploaded to OpenAlex/works_encoded/new_works_encoded_12.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from tqdm import tqdm\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \n",
    "    path_to_private_key = \"/home/fs01/spec1142/Emma/openalex-lee-c532eb059285.json\"\n",
    "    client_storage = storage.Client.from_service_account_json(json_credentials_path=path_to_private_key)\n",
    "    bucket = client_storage.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, destination_blob_name\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "for k in tqdm(range(13)):\n",
    "    bucket_name = 'openalex-lee'\n",
    "    destination_blob_name = \"OpenAlex/works_encoded/\" + \"new_works_encoded_\" + str(k) + \".tsv\"\n",
    "    source_file_name = main_path + \"new_works_encoded_\" + str(k) + \".tsv\"\n",
    "    upload_blob(bucket_name, source_file_name, destination_blob_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834e56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
